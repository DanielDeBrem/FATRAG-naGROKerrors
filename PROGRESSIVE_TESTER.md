# ðŸ§ª Progressive Quality Tester

**De gemakkelijkste manier om optimale configuraties te vinden!**

## ðŸŽ¯ Wat doet het?

Start met de **kleinste, snelste** configuratie en schaalt automatisch op naar betere kwaliteit:

```
Level 1: Minimal  âš¡ â†’ Snel (30s-5m)
  â†“ (bij succes)
Level 2: Balanced âš™ï¸ â†’ Gemiddeld (60s-10m)
  â†“ (bij succes)
Level 3: Maximum  ðŸš€ â†’ Beste kwaliteit (90s-30m)
```

**Stopt automatisch** bij falen, zodat je niet onnodig tijd verliest!

## ðŸ“ Open de Tester

```
http://10.0.1.227:8020/admin/progressive-test.html
```

## ðŸŽ® Hoe te gebruiken

1. **Kies analyse type:**
   - âš¡ Flash Analysis (3 levels: 30s â†’ 60s â†’ 90s)
   - ðŸ“š Grondige Analyse (3 levels: 5m â†’ 10m â†’ 15m)
   - ðŸ“‹ Template Report (3 levels: 10m â†’ 20m â†’ 30m)

2. **Klik "Start Progressive Test"**
   - Level 1 draait automatisch
   - Bij succes â†’ Level 2 draait automatisch
   - Bij succes â†’ Level 3 draait automatisch
   - Bij falen â†’ Stopt en toont resultaten

3. **Bekijk resultaten:**
   - Tijd per level
   - Tokens verbruik
   - Quality score
   - **Aanbevolen configuratie** voor productie

4. **Klik "Bekijk in Dashboard"** voor historische data

## ðŸŽ¨ Features

âœ… **Auto-progression** - Geen manual clicks tussen levels
âœ… **Smart stopping** - Stopt bij eerste fail
âœ… **Visual feedback** - Spinners, progress bar, status icons
âœ… **Real-time results** - Zie metrics direct per level
âœ… **Recommendation engine** - Krijg beste config aanbevolen
âœ… **Stop button** - Cancel test mid-run
âœ… **Reset** - Start opnieuw met Ã©Ã©n klik

## ðŸ“Š Test Configs per Type

### Flash Analysis (llama3.1:8b)
```javascript
Level 1: Mini      â†’ temp=0.1, tokens=1500  (snelst)
Level 2: Standard  â†’ temp=0.15, tokens=2500 (balanced)
Level 3: Max       â†’ temp=0.2, tokens=3000  (beste)
```

###  Grondige Analyse (llama3.1:70b)
```javascript
Level 1: Snel      â†’ temp=0.05, chunks=1500 (snelst)
Level 2: Balanced  â†’ temp=0.1, chunks=2500  (balanced)
Level 3: Diep      â†’ temp=0.15, chunks=3500 (beste)
```

### Template Report (llama3.1:70b)
```javascript
Level 1: Basis    â†’ temp=0.05, sequential   (snelst)
Level 2: Plus     â†’ temp=0.1, parallel      (balanced)
Level 3: Premium  â†’ temp=0.15, parallel     (beste)
```

## ðŸŽ¯ Typische Workflow

1. **Flash test eerst** (snel, 2-6 minuten)
   - Verifieer systeem werkt
   - Vind baseline

2. **Grondige als Flash succesvol** (15-45 minuten)
   - Test 70B model
   - Vind optimale chunk size

3. **Template voor finale tuning** (30-90 minuten)
   - Test parallel vs sequential
   - Vind optimale temperature

## ðŸ’¡ Wat de test output betekent

**Bij Level 1 fail:**
- Ollama problemen
- Model niet beschikbaar
- Configuration errors
â†’ Fix infrastructuur eerst

**Bij Level 2 fail:**
- Model overload
- Timeout issues
- Memory problemen
â†’ Level 1 is je productie config

**Bij Level 3 fail:**
- Edge case van model
- Extreme parameters
â†’ Level 2 is je productie config

**Alles succesvol:**
- ðŸŽ‰ Level 3 is je productie config!
- Beste kwaliteit haalbaar

## ðŸš€ Na testen

1. Noteer aanbevolen config
2. Update je productie code met die settings
3. Monitor performance in Dashboard
4. Herhaal test weekly voor optimization

## ðŸ”§ Mode: Demo vs Production

**Nu: DEMO MODE**
- Simulated tests (3-5s per level)
- Random success/fail
- Fake metrics

**TODO: Production Mode**
- Daadwerkelijke analyse runs
- Echte Ollama calls
- Real metrics naar MetricsStore

Vervang in JavaScript:
```javascript
// Replace deze simulate code:
await sleep(3000);
const success = Math.random() > 0.1;

// Met dit:
const result = await fetch('/api/progressive-test', {
  method: 'POST',
  body: JSON.stringify({type, level, config})
});
```

## ðŸ“‚ Files

```
static/admin/progressive-test.html  â†’ Main UI
metrics_store.py                    â†’ Metrics opslag
scripts/auto_test_analyses.py      â†’ CLI versie
```

## ðŸŽ¨ Design Features

- Gradient background
- Animated spinners
- Smooth progress bar
- Color-coded feedback:
  - ðŸŸ¡ Yellow = Waiting
  - ðŸ”µ Blue = Running
  - ðŸŸ¢ Green = Success
  - ðŸ”´ Red = Failed
- Responsive mobile-first
- Tailwind CSS styling

## ðŸ“ž Quick Links

- Progressive Tester: `/admin/progressive-test.html`
- Monitoring Dashboard: `/admin/monitor.html`
- Main Admin: `/admin/index.html`
- Docs: `MONITORING_README.md`

---

**TIP:** Begin altijd met Flash Analysis om je systeem te verifiÃ«ren! ðŸš€

## ðŸ”§ Parameter Tuning (Multiâ€‘GPU, 8Ã— RTX 3060 Ti)

Gebruik de tuner om automatisch de beste parameters te vinden en op te slaan voor de FATRAG pipeline met 1 GPU per trial (kleine modellen) en GPUâ€‘bewuste instellingen.

- Endpoint: `POST /api/progressive-test/tune`
- Vereisten:
  1) Start 8 Ollama workers (1 GPU per port 11434..11441):
     `bash scripts/start_ollama_workers.sh`
  2) Zorg dat de FastAPI server draait op poort 8020
- Voorbeeld body:
```json
{
  "project_id": "project-XXXX",
  "search_space": {
    "model": ["llama3.1:8b"],
    "temperature": [0.1, 0.15, 0.2],
    "max_tokens": [1536, 2048, 3072],
    "max_chunks": [15, 25, 35],
    "chunk_size": [600, 800, 1000, 1200],
    "chunk_overlap": [25, 50, 100, 200],
    "concurrency": [1, 2]
  },
  "objective": "maximize_chunks_per_second",
  "budget": { "max_trials": 8, "max_total_runtime_seconds": 1800, "early_stopping_rounds": 3 },
  "persist": true
}
```
- Smoke test:
  `python3 scripts/smoke_tuner.py --project-id project-XXXX --persist`
- Resultaat:
  - Beste configuratie + score + volledige trialâ€‘historie
  - Bij `"persist": true` worden de winnende instellingen onder `FLASH_TUNING` in `config/config.json` opgeslagen en runtime herladen

GPUâ€‘best practices (3060 Ti, 8 GB VRAM):
- Kleine modellen (7B/8B) voor snelle trials; `concurrency` op 1â€“2 houden
- `max_tokens` 1536â€“3072, `chunk_size` 600â€“1200, `chunk_overlap` 25â€“200
- 70B alleen voor finale synthese indien gewenst; zonder NVLink is singleâ€‘GPU 70B traag â€” paralleliseer overige taken over de andere 7 GPUâ€™s
